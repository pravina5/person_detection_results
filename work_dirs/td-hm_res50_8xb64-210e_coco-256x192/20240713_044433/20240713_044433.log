2024/07/13 04:44:36 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: False
    MUSA available: False
    numpy_random_seed: 699537575
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.3.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.18.1
    OpenCV: 4.10.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 699537575
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/07/13 04:44:36 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=512)
backend_args = dict(backend='local')
codec = dict(
    heatmap_size=(
        48,
        64,
    ),
    input_size=(
        192,
        256,
    ),
    sigma=2,
    type='MSRAHeatmap')
custom_hooks = [
    dict(type='SyncBuffersHook'),
]
data_mode = 'topdown'
data_root = 'data/coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    badcase=dict(
        badcase_thr=5,
        enable=False,
        metric_type='loss',
        out_dir='badcase',
        type='BadCaseAnalysisHook'),
    checkpoint=dict(
        interval=10,
        rule='greater',
        save_best='coco/AP',
        type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(enable=False, type='PoseVisualizationHook'))
default_scope = 'mmpose'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(
    by_epoch=True, num_digits=6, type='LogProcessor', window_size=50)
model = dict(
    backbone=dict(
        depth=50,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='PoseDataPreprocessor'),
    head=dict(
        decoder=dict(
            heatmap_size=(
                48,
                64,
            ),
            input_size=(
                192,
                256,
            ),
            sigma=2,
            type='MSRAHeatmap'),
        in_channels=2048,
        loss=dict(type='KeypointMSELoss', use_target_weight=True),
        out_channels=17,
        type='HeatmapHead'),
    test_cfg=dict(flip_mode='heatmap', flip_test=True, shift_heatmap=True),
    type='TopdownPoseEstimator')
optim_wrapper = dict(optimizer=dict(lr=0.0005, type='Adam'))
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=210,
        gamma=0.1,
        milestones=[
            170,
            200,
        ],
        type='MultiStepLR'),
]
resume = False
test_cfg = dict()
test_dataloader = dict(
    batch_size=32,
    dataset=dict(
        ann_file='annotations/person_keypoints_val2017.json',
        bbox_file=
        'data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json',
        data_mode='topdown',
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(type='LoadImage'),
            dict(type='GetBBoxCenterScale'),
            dict(input_size=(
                192,
                256,
            ), type='TopdownAffine'),
            dict(type='PackPoseInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(round_up=False, shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='data/coco/annotations/person_keypoints_val2017.json',
    type='CocoMetric')
train_cfg = dict(by_epoch=True, max_epochs=210, val_interval=10)
train_dataloader = dict(
    batch_size=64,
    dataset=dict(
        ann_file='annotations/person_keypoints_train2017.json',
        data_mode='topdown',
        data_prefix=dict(img='train2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(type='LoadImage'),
            dict(type='GetBBoxCenterScale'),
            dict(direction='horizontal', type='RandomFlip'),
            dict(type='RandomHalfBody'),
            dict(type='RandomBBoxTransform'),
            dict(input_size=(
                192,
                256,
            ), type='TopdownAffine'),
            dict(
                encoder=dict(
                    heatmap_size=(
                        48,
                        64,
                    ),
                    input_size=(
                        192,
                        256,
                    ),
                    sigma=2,
                    type='MSRAHeatmap'),
                type='GenerateTarget'),
            dict(type='PackPoseInputs'),
        ],
        type='CocoDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImage'),
    dict(type='GetBBoxCenterScale'),
    dict(direction='horizontal', type='RandomFlip'),
    dict(type='RandomHalfBody'),
    dict(type='RandomBBoxTransform'),
    dict(input_size=(
        192,
        256,
    ), type='TopdownAffine'),
    dict(
        encoder=dict(
            heatmap_size=(
                48,
                64,
            ),
            input_size=(
                192,
                256,
            ),
            sigma=2,
            type='MSRAHeatmap'),
        type='GenerateTarget'),
    dict(type='PackPoseInputs'),
]
val_cfg = dict()
val_dataloader = dict(
    batch_size=32,
    dataset=dict(
        ann_file='annotations/person_keypoints_val2017.json',
        bbox_file=
        'data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json',
        data_mode='topdown',
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(type='LoadImage'),
            dict(type='GetBBoxCenterScale'),
            dict(input_size=(
                192,
                256,
            ), type='TopdownAffine'),
            dict(type='PackPoseInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(round_up=False, shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='data/coco/annotations/person_keypoints_val2017.json',
    type='CocoMetric')
val_pipeline = [
    dict(type='LoadImage'),
    dict(type='GetBBoxCenterScale'),
    dict(input_size=(
        192,
        256,
    ), type='TopdownAffine'),
    dict(type='PackPoseInputs'),
]
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='PoseLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/td-hm_res50_8xb64-210e_coco-256x192'

2024/07/13 04:44:37 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/07/13 04:44:37 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) PoseVisualizationHook              
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) PoseVisualizationHook              
(NORMAL      ) BadCaseAnalysisHook                
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) BadCaseAnalysisHook                
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/07/13 04:45:50 - mmengine - INFO - load model from: torchvision://resnet50
2024/07/13 04:45:50 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2024/07/13 04:45:50 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

head.deconv_layers.0.weight - torch.Size([2048, 256, 4, 4]): 
NormalInit: mean=0, std=0.001, bias=0 

head.deconv_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.deconv_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.deconv_layers.3.weight - torch.Size([256, 256, 4, 4]): 
NormalInit: mean=0, std=0.001, bias=0 

head.deconv_layers.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.deconv_layers.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.deconv_layers.6.weight - torch.Size([256, 256, 4, 4]): 
NormalInit: mean=0, std=0.001, bias=0 

head.deconv_layers.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.deconv_layers.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of TopdownPoseEstimator  

head.final_layer.weight - torch.Size([17, 256, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

head.final_layer.bias - torch.Size([17]): 
NormalInit: mean=0, std=0.001, bias=0 
2024/07/13 04:45:51 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/07/13 04:45:51 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/07/13 04:45:51 - mmengine - INFO - Checkpoints will be saved to /home/stu3/s8/rt6579/mmpose/work_dirs/td-hm_res50_8xb64-210e_coco-256x192.
2024/07/13 04:50:31 - mmengine - INFO - Epoch(train)   [1][  50/2341]  lr: 4.954910e-05  eta: 31 days, 21:34:38  time: 5.606800  data_time: 0.145638  loss: 0.002186  loss_kpt: 0.002186  acc_pose: 0.136692
2024/07/13 04:55:10 - mmengine - INFO - Epoch(train)   [1][ 100/2341]  lr: 9.959920e-05  eta: 31 days, 19:39:42  time: 5.579881  data_time: 0.124238  loss: 0.001984  loss_kpt: 0.001984  acc_pose: 0.222119
2024/07/13 04:59:53 - mmengine - INFO - Epoch(train)   [1][ 150/2341]  lr: 1.496493e-04  eta: 31 days, 22:20:16  time: 5.653855  data_time: 0.147545  loss: 0.001811  loss_kpt: 0.001811  acc_pose: 0.313597
2024/07/13 05:04:33 - mmengine - INFO - Epoch(train)   [1][ 200/2341]  lr: 1.996994e-04  eta: 31 days, 21:56:32  time: 5.604201  data_time: 0.130882  loss: 0.001726  loss_kpt: 0.001726  acc_pose: 0.357841
2024/07/13 05:09:16 - mmengine - INFO - Epoch(train)   [1][ 250/2341]  lr: 2.497495e-04  eta: 31 days, 23:22:48  time: 5.666711  data_time: 0.131604  loss: 0.001668  loss_kpt: 0.001668  acc_pose: 0.392518
2024/07/13 05:14:02 - mmengine - INFO - Epoch(train)   [1][ 300/2341]  lr: 2.997996e-04  eta: 32 days, 1:30:47  time: 5.719503  data_time: 0.137293  loss: 0.001653  loss_kpt: 0.001653  acc_pose: 0.392276
2024/07/13 05:18:47 - mmengine - INFO - Epoch(train)   [1][ 350/2341]  lr: 3.498497e-04  eta: 32 days, 2:31:54  time: 5.694762  data_time: 0.155709  loss: 0.001618  loss_kpt: 0.001618  acc_pose: 0.394124
2024/07/13 05:23:32 - mmengine - INFO - Epoch(train)   [1][ 400/2341]  lr: 3.998998e-04  eta: 32 days, 3:14:31  time: 5.692772  data_time: 0.131419  loss: 0.001577  loss_kpt: 0.001577  acc_pose: 0.393631
2024/07/13 05:28:15 - mmengine - INFO - Epoch(train)   [1][ 450/2341]  lr: 4.499499e-04  eta: 32 days, 3:20:11  time: 5.663721  data_time: 0.130483  loss: 0.001549  loss_kpt: 0.001549  acc_pose: 0.382015
2024/07/13 05:32:58 - mmengine - INFO - Epoch(train)   [1][ 500/2341]  lr: 5.000000e-04  eta: 32 days, 3:22:41  time: 5.662383  data_time: 0.173057  loss: 0.001544  loss_kpt: 0.001544  acc_pose: 0.455681
2024/07/13 05:37:43 - mmengine - INFO - Epoch(train)   [1][ 550/2341]  lr: 5.000000e-04  eta: 32 days, 3:57:45  time: 5.707928  data_time: 0.132950  loss: 0.001545  loss_kpt: 0.001545  acc_pose: 0.413108
2024/07/13 05:42:28 - mmengine - INFO - Epoch(train)   [1][ 600/2341]  lr: 5.000000e-04  eta: 32 days, 4:15:56  time: 5.692887  data_time: 0.135314  loss: 0.001530  loss_kpt: 0.001530  acc_pose: 0.408093
2024/07/13 05:47:15 - mmengine - INFO - Epoch(train)   [1][ 650/2341]  lr: 5.000000e-04  eta: 32 days, 4:56:24  time: 5.733916  data_time: 0.128033  loss: 0.001490  loss_kpt: 0.001490  acc_pose: 0.421822
2024/07/13 05:51:58 - mmengine - INFO - Epoch(train)   [1][ 700/2341]  lr: 5.000000e-04  eta: 32 days, 4:46:58  time: 5.659573  data_time: 0.146307  loss: 0.001466  loss_kpt: 0.001466  acc_pose: 0.468255
2024/07/13 05:56:42 - mmengine - INFO - Epoch(train)   [1][ 750/2341]  lr: 5.000000e-04  eta: 32 days, 4:49:44  time: 5.680790  data_time: 0.129319  loss: 0.001477  loss_kpt: 0.001477  acc_pose: 0.473183
2024/07/13 06:01:25 - mmengine - INFO - Epoch(train)   [1][ 800/2341]  lr: 5.000000e-04  eta: 32 days, 4:42:19  time: 5.662728  data_time: 0.127824  loss: 0.001455  loss_kpt: 0.001455  acc_pose: 0.463940
2024/07/13 06:06:07 - mmengine - INFO - Epoch(train)   [1][ 850/2341]  lr: 5.000000e-04  eta: 32 days, 4:29:53  time: 5.651627  data_time: 0.146142  loss: 0.001430  loss_kpt: 0.001430  acc_pose: 0.461358
2024/07/13 06:10:47 - mmengine - INFO - Epoch(train)   [1][ 900/2341]  lr: 5.000000e-04  eta: 32 days, 3:55:16  time: 5.600922  data_time: 0.129855  loss: 0.001403  loss_kpt: 0.001403  acc_pose: 0.500570
2024/07/13 06:15:25 - mmengine - INFO - Epoch(train)   [1][ 950/2341]  lr: 5.000000e-04  eta: 32 days, 3:04:33  time: 5.556153  data_time: 0.131489  loss: 0.001401  loss_kpt: 0.001401  acc_pose: 0.498853
2024/07/13 06:20:04 - mmengine - INFO - Exp name: td-hm_res50_8xb64-210e_coco-256x192_20240713_044433
2024/07/13 06:20:04 - mmengine - INFO - Epoch(train)   [1][1000/2341]  lr: 5.000000e-04  eta: 32 days, 2:22:49  time: 5.566899  data_time: 0.124454  loss: 0.001404  loss_kpt: 0.001404  acc_pose: 0.460866
2024/07/13 06:24:45 - mmengine - INFO - Epoch(train)   [1][1050/2341]  lr: 5.000000e-04  eta: 32 days, 2:12:11  time: 5.637696  data_time: 0.143272  loss: 0.001385  loss_kpt: 0.001385  acc_pose: 0.470707
2024/07/13 06:29:24 - mmengine - INFO - Epoch(train)   [1][1100/2341]  lr: 5.000000e-04  eta: 32 days, 1:39:41  time: 5.577362  data_time: 0.128513  loss: 0.001380  loss_kpt: 0.001380  acc_pose: 0.519785
2024/07/13 06:34:03 - mmengine - INFO - Epoch(train)   [1][1150/2341]  lr: 5.000000e-04  eta: 32 days, 1:11:21  time: 5.582313  data_time: 0.144817  loss: 0.001351  loss_kpt: 0.001351  acc_pose: 0.511501
2024/07/13 06:38:43 - mmengine - INFO - Epoch(train)   [1][1200/2341]  lr: 5.000000e-04  eta: 32 days, 0:47:32  time: 5.589769  data_time: 0.123844  loss: 0.001364  loss_kpt: 0.001364  acc_pose: 0.542502
2024/07/13 06:43:24 - mmengine - INFO - Epoch(train)   [1][1250/2341]  lr: 5.000000e-04  eta: 32 days, 0:36:40  time: 5.624692  data_time: 0.140318  loss: 0.001335  loss_kpt: 0.001335  acc_pose: 0.480545
2024/07/13 06:48:01 - mmengine - INFO - Epoch(train)   [1][1300/2341]  lr: 5.000000e-04  eta: 31 days, 23:55:19  time: 5.526195  data_time: 0.128794  loss: 0.001349  loss_kpt: 0.001349  acc_pose: 0.546502
2024/07/13 06:52:43 - mmengine - INFO - Epoch(train)   [1][1350/2341]  lr: 5.000000e-04  eta: 31 days, 23:55:55  time: 5.655799  data_time: 0.144598  loss: 0.001363  loss_kpt: 0.001363  acc_pose: 0.561630
2024/07/13 06:57:21 - mmengine - INFO - Epoch(train)   [1][1400/2341]  lr: 5.000000e-04  eta: 31 days, 23:24:58  time: 5.548997  data_time: 0.150982  loss: 0.001326  loss_kpt: 0.001326  acc_pose: 0.508298
2024/07/13 07:02:03 - mmengine - INFO - Epoch(train)   [1][1450/2341]  lr: 5.000000e-04  eta: 31 days, 23:24:00  time: 5.649027  data_time: 0.137086  loss: 0.001312  loss_kpt: 0.001312  acc_pose: 0.500990
2024/07/13 07:06:42 - mmengine - INFO - Epoch(train)   [1][1500/2341]  lr: 5.000000e-04  eta: 31 days, 23:05:37  time: 5.585945  data_time: 0.134152  loss: 0.001312  loss_kpt: 0.001312  acc_pose: 0.578805
2024/07/13 07:11:27 - mmengine - INFO - Epoch(train)   [1][1550/2341]  lr: 5.000000e-04  eta: 31 days, 23:13:43  time: 5.683070  data_time: 0.136714  loss: 0.001317  loss_kpt: 0.001317  acc_pose: 0.573881
2024/07/13 07:16:07 - mmengine - INFO - Epoch(train)   [1][1600/2341]  lr: 5.000000e-04  eta: 31 days, 23:03:45  time: 5.615405  data_time: 0.152828  loss: 0.001313  loss_kpt: 0.001313  acc_pose: 0.532756
2024/07/13 07:20:49 - mmengine - INFO - Epoch(train)   [1][1650/2341]  lr: 5.000000e-04  eta: 31 days, 22:59:57  time: 5.639077  data_time: 0.135797  loss: 0.001328  loss_kpt: 0.001328  acc_pose: 0.529831
2024/07/13 07:25:34 - mmengine - INFO - Epoch(train)   [1][1700/2341]  lr: 5.000000e-04  eta: 31 days, 23:09:43  time: 5.695814  data_time: 0.133937  loss: 0.001287  loss_kpt: 0.001287  acc_pose: 0.572989
2024/07/13 07:30:14 - mmengine - INFO - Epoch(train)   [1][1750/2341]  lr: 5.000000e-04  eta: 31 days, 22:53:13  time: 5.586716  data_time: 0.132650  loss: 0.001333  loss_kpt: 0.001333  acc_pose: 0.515330
2024/07/13 07:34:55 - mmengine - INFO - Epoch(train)   [1][1800/2341]  lr: 5.000000e-04  eta: 31 days, 22:48:24  time: 5.635341  data_time: 0.151454  loss: 0.001311  loss_kpt: 0.001311  acc_pose: 0.531190
2024/07/13 07:39:38 - mmengine - INFO - Epoch(train)   [1][1850/2341]  lr: 5.000000e-04  eta: 31 days, 22:46:04  time: 5.646626  data_time: 0.139242  loss: 0.001291  loss_kpt: 0.001291  acc_pose: 0.605522
2024/07/13 07:44:17 - mmengine - INFO - Epoch(train)   [1][1900/2341]  lr: 5.000000e-04  eta: 31 days, 22:29:20  time: 5.580126  data_time: 0.135148  loss: 0.001287  loss_kpt: 0.001287  acc_pose: 0.471870
2024/07/13 07:49:01 - mmengine - INFO - Epoch(train)   [1][1950/2341]  lr: 5.000000e-04  eta: 31 days, 22:35:34  time: 5.686860  data_time: 0.153737  loss: 0.001283  loss_kpt: 0.001283  acc_pose: 0.607580
2024/07/13 07:53:44 - mmengine - INFO - Exp name: td-hm_res50_8xb64-210e_coco-256x192_20240713_044433
2024/07/13 07:53:44 - mmengine - INFO - Epoch(train)   [1][2000/2341]  lr: 5.000000e-04  eta: 31 days, 22:36:29  time: 5.663590  data_time: 0.129690  loss: 0.001280  loss_kpt: 0.001280  acc_pose: 0.558264
2024/07/13 07:58:28 - mmengine - INFO - Epoch(train)   [1][2050/2341]  lr: 5.000000e-04  eta: 31 days, 22:38:10  time: 5.668750  data_time: 0.126878  loss: 0.001270  loss_kpt: 0.001270  acc_pose: 0.507045
2024/07/13 08:03:11 - mmengine - INFO - Epoch(train)   [1][2100/2341]  lr: 5.000000e-04  eta: 31 days, 22:40:41  time: 5.674585  data_time: 0.130723  loss: 0.001287  loss_kpt: 0.001287  acc_pose: 0.591684
2024/07/13 08:07:57 - mmengine - INFO - Epoch(train)   [1][2150/2341]  lr: 5.000000e-04  eta: 31 days, 22:48:36  time: 5.704943  data_time: 0.151479  loss: 0.001280  loss_kpt: 0.001280  acc_pose: 0.583466
2024/07/13 08:12:36 - mmengine - INFO - Epoch(train)   [1][2200/2341]  lr: 5.000000e-04  eta: 31 days, 22:35:40  time: 5.595478  data_time: 0.125768  loss: 0.001258  loss_kpt: 0.001258  acc_pose: 0.552012
2024/07/13 08:17:16 - mmengine - INFO - Epoch(train)   [1][2250/2341]  lr: 5.000000e-04  eta: 31 days, 22:21:09  time: 5.584723  data_time: 0.130565  loss: 0.001256  loss_kpt: 0.001256  acc_pose: 0.575695
2024/07/13 08:21:58 - mmengine - INFO - Epoch(train)   [1][2300/2341]  lr: 5.000000e-04  eta: 31 days, 22:18:59  time: 5.651967  data_time: 0.133380  loss: 0.001256  loss_kpt: 0.001256  acc_pose: 0.480164
2024/07/13 08:25:47 - mmengine - INFO - Exp name: td-hm_res50_8xb64-210e_coco-256x192_20240713_044433
2024/07/13 08:30:22 - mmengine - INFO - Epoch(train)   [2][  50/2341]  lr: 5.000000e-04  eta: 31 days, 21:39:46  time: 5.501657  data_time: 0.133445  loss: 0.001237  loss_kpt: 0.001237  acc_pose: 0.522523
2024/07/13 08:34:55 - mmengine - INFO - Epoch(train)   [2][ 100/2341]  lr: 5.000000e-04  eta: 31 days, 21:04:32  time: 5.451405  data_time: 0.121254  loss: 0.001237  loss_kpt: 0.001237  acc_pose: 0.491722
2024/07/13 08:39:33 - mmengine - INFO - Epoch(train)   [2][ 150/2341]  lr: 5.000000e-04  eta: 31 days, 20:50:27  time: 5.573079  data_time: 0.145164  loss: 0.001238  loss_kpt: 0.001238  acc_pose: 0.573150
2024/07/13 08:44:08 - mmengine - INFO - Epoch(train)   [2][ 200/2341]  lr: 5.000000e-04  eta: 31 days, 20:24:59  time: 5.499869  data_time: 0.128806  loss: 0.001239  loss_kpt: 0.001239  acc_pose: 0.583479
2024/07/13 08:48:43 - mmengine - INFO - Epoch(train)   [2][ 250/2341]  lr: 5.000000e-04  eta: 31 days, 19:59:36  time: 5.495186  data_time: 0.124309  loss: 0.001233  loss_kpt: 0.001233  acc_pose: 0.667848
2024/07/13 08:53:23 - mmengine - INFO - Epoch(train)   [2][ 300/2341]  lr: 5.000000e-04  eta: 31 days, 19:51:48  time: 5.604130  data_time: 0.128110  loss: 0.001240  loss_kpt: 0.001240  acc_pose: 0.566207
2024/07/13 08:57:58 - mmengine - INFO - Epoch(train)   [2][ 350/2341]  lr: 5.000000e-04  eta: 31 days, 19:28:30  time: 5.500958  data_time: 0.125615  loss: 0.001214  loss_kpt: 0.001214  acc_pose: 0.595412
2024/07/13 09:02:34 - mmengine - INFO - Epoch(train)   [2][ 400/2341]  lr: 5.000000e-04  eta: 31 days, 19:06:55  time: 5.507858  data_time: 0.127136  loss: 0.001207  loss_kpt: 0.001207  acc_pose: 0.538006
2024/07/13 09:07:09 - mmengine - INFO - Epoch(train)   [2][ 450/2341]  lr: 5.000000e-04  eta: 31 days, 18:44:34  time: 5.498487  data_time: 0.124672  loss: 0.001235  loss_kpt: 0.001235  acc_pose: 0.605276
2024/07/13 09:11:48 - mmengine - INFO - Epoch(train)   [2][ 500/2341]  lr: 5.000000e-04  eta: 31 days, 18:35:04  time: 5.583745  data_time: 0.128345  loss: 0.001203  loss_kpt: 0.001203  acc_pose: 0.556993
2024/07/13 09:16:26 - mmengine - INFO - Epoch(train)   [2][ 550/2341]  lr: 5.000000e-04  eta: 31 days, 18:22:03  time: 5.557665  data_time: 0.146659  loss: 0.001209  loss_kpt: 0.001209  acc_pose: 0.587466
2024/07/13 09:21:01 - mmengine - INFO - Epoch(train)   [2][ 600/2341]  lr: 5.000000e-04  eta: 31 days, 18:00:43  time: 5.495450  data_time: 0.124996  loss: 0.001205  loss_kpt: 0.001205  acc_pose: 0.576206
2024/07/13 09:25:35 - mmengine - INFO - Epoch(train)   [2][ 650/2341]  lr: 5.000000e-04  eta: 31 days, 17:38:43  time: 5.486477  data_time: 0.119847  loss: 0.001207  loss_kpt: 0.001207  acc_pose: 0.559468
2024/07/13 09:26:25 - mmengine - INFO - Exp name: td-hm_res50_8xb64-210e_coco-256x192_20240713_044433
2024/07/13 09:30:12 - mmengine - INFO - Epoch(train)   [2][ 700/2341]  lr: 5.000000e-04  eta: 31 days, 17:23:31  time: 5.532963  data_time: 0.124944  loss: 0.001192  loss_kpt: 0.001192  acc_pose: 0.558351
2024/07/13 09:34:48 - mmengine - INFO - Epoch(train)   [2][ 750/2341]  lr: 5.000000e-04  eta: 31 days, 17:06:40  time: 5.517908  data_time: 0.143020  loss: 0.001194  loss_kpt: 0.001194  acc_pose: 0.660103
2024/07/13 09:39:25 - mmengine - INFO - Epoch(train)   [2][ 800/2341]  lr: 5.000000e-04  eta: 31 days, 16:54:52  time: 5.553688  data_time: 0.123953  loss: 0.001224  loss_kpt: 0.001224  acc_pose: 0.583150
2024/07/13 09:44:01 - mmengine - INFO - Epoch(train)   [2][ 850/2341]  lr: 5.000000e-04  eta: 31 days, 16:38:50  time: 5.518860  data_time: 0.122556  loss: 0.001231  loss_kpt: 0.001231  acc_pose: 0.582348
